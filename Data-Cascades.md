# “Every one wants to do the model work, not the data work”: Data Cascades in High-Stakes AI

Nithya Sambasivan, et. al. Google Research

## 0. ABSTRACT

AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades—compounding events causing negative, downstream effects from data issues—triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.

AI模型正越来越多的在高风险领域中应用，比如健康和环境保护。数据质量在高风险AI中的重要性也越来越高，因为其对下游的影响非常大，影响了像癌症检测、野生动物偷猎，和信贷资金配置方式。最为荒谬的是，数据是AI中最为低估，最为无光彩的部分。本文中，我们给出高风险AI中的数据实践，对印度，东非和西非国家，和USA的53个AI实践者进行了采访。我们定义，识别并给出数据级联的经验证据，从数据的问题中复合的事件导致负面效果，由传统的AI/ML实践中低估了数据的质量。数据级联到处都是(92%普遍率)，不可见，被延迟，但通常都是可以避免的。我们讨论了在设计、激励数据重要性，作为AI的一等公民中，HCI中的机会，对所有领域得到了更安全更稳健的系统。

**KEYWORDS** Data, AI, ML, high-stakes AI, data cascades, developers, raters, application-domain experts, data collectors, data quality, data politics, India, Nigeria, Kenya, Ghana, Uganda, USA

## 1. INTRODUCTION

Data is the critical infrastructure necessary to build Artificial Intelligence (AI) systems [44]. Data largely determines performance, fairness, robustness, safety, and scalability of AI systems [44, 81]. Paradoxically, for AI researchers and developers, data is often the least incentivized aspect, viewed as 'operational' relative to the lionized work of building novel models and algorithms [46, 125]. Intuitively, AI developers understand that data quality matters, often spending inordinate amounts of time on data tasks [60]. In practice, most organisations fail to create or meet any data quality standards [87], from under-valuing data work vis-a-vis model development.

数据是关键的基础设施，是构建AI系统所必须的。数据大致决定了AI系统的性能，公平性，稳健性，安全性和可扩展性。矛盾的是，对于AI研究者和开发者，数据通常是最不被鼓励的方面，与构建新模型和新算法这样的工作相比，被视为是运作上的工作。直觉上来说，AI开发者理解，数据质量非常重要，通常要在数据任务上花费非常多的时间。在实践中，多数组织没有创建或达到任何数据质量标准，低估的数据工作，与模型开发形成对比。

Under-valuing of data work is common to all of AI development [125]. We pay particular attention to undervaluing of data in high-stakes domains that have safety impacts on living beings, due to a few reasons. One, developers are increasingly deploying AI models in complex, humanitarian domains, e.g., in maternal health, road safety, and climate change. Two, poor data quality in high-stakes domains can have outsized effects on vulnerable communities and contexts. As Hiatt et al. argue, high-stakes efforts are distinct from serving customers; these projects work with and for populations at risk of a litany of horrors [47]. As an example, poor data practices reduced accuracy in IBM’s cancer treatment AI [115] and led to Google Flu Trends missing the flu peak by 140% [63, 73]). Three, high-stakes AI systems are typically deployed in low-resource contexts with a pronounced lack of readily available, high-quality datasets. Applications span into communities that live outside of a modern data infrastructure, or where everyday functions are not yet consistently tracked, e.g., walking distances to gather water in rural areas—in contrast to, say, click data [26]. Finally, high-stakes AI is more often created at the combination of two or more disciplines; for example, AI and diabetic retinopathy, leading to greater collaboration challenges among stakeholders across organizations and domains [75, 121].

数据工作的低估，是所有AI开发工作很常见的。由于一些原因，我们对高风险领域中的数据低估情况进行特别的关注，这些领域会对生物有安全影响。一个是，开发者正越来越多的在复杂的慈善领域部署AI模型，如孕妇健康，道路安全，和气候变化。第二，高风险领域中很差的数据质量，对脆弱的团体和上下文有非常大的影响。就像Hiatt等所说，高风险的努力与服务客户是不一样的；这些工程是会影响很多人的。比如，很差的数据实践降低了IBM的癌症诊断AI的准确率，使Google Flu Trends错过了flu峰值140%。第三，高风险AI系统一般是在低资源的环境中部署，非常缺少即时可用的、高质量数据集。应用会扩展到缺少现代数据基础设施的团体，或每天的功能并不是连续跟踪的，如，在农村地区走路去取水，或点击数据。最后，高风险AI通常是结合了两个或更多的原则进行创建的；比如，AI和糖尿病视网膜症，带来了不同组织和领域的人的更复杂的挑战。

Considering the above factors, currently data quality issues in AI are addressed with the wrong tools created for, and fitted to other technology problems—they are approached as a database problem, legal compliance issue, or licensing deal. HCI and CSCW scholarship have long examined the practices of collaboration, problem formulation, and sensemaking, by humans behind the datasets, including data collectors and scientists, [69, 86, 127], and are designing computational artefacts for dataset development [53]. Our research extends this scholarship by empirically examining data practices and challenges of high-stakes AI practitioners impacting vulnerable groups.

考虑到上面的因素，目前AI中的数据质量问题，处理的工具是错误的，是适用于其他技术问题的，它们被当做一个数据库问题处理，遵守法律的问题，或许可权的问题。HCI和CSCW已经研究合作，问题表述和有意义的实践很久了，通过数据集背后的人，包括数据收集者和科学家，设计计算上的人造物品以进行数据集开发。我们的研究对此进行了拓展，从经验上检查高风险AI实践者的数据实践和挑战，这些行为会影响脆弱的团体。

We report our results from a qualitative study on practices and structural factors among 53 AI practitioners in India, the US, and East and West African countries, applying AI to high-stakes domains including landslide detection, suicide prevention, and cancer detection. Our research aimed to understand how practitioners conceptualised and navigated the end-to-end AI data life cycles.

我们对53个AI实践者的实践和结构因素进行了定性研究，给出结果，这些实践者是在印度，美国，东非、西非国家，将AI应用到高风险领域，包括山体滑坡检测，自杀预防，和癌症检测。我们的研究目标是，理解实践者怎样对端到端的AI数据生命循环进行理解和进行。

In this paper, we define and identify Data Cascades: compounding events causing negative, downstream effects from data issues, resulting in technical debt over time. In our study, data cascades were widely prevalent: 92% of AI practitioners reported experiencing one or more, and 45.3% reported two or more cascades in a given project. Data cascades often resulted from applying conventional AI practices that undervalued data quality. For example, eye disease detection models, trained on noise-free training data for high model performance, failed to predict the disease in production upon small specks of dust on images. Data cascades were opaque and delayed, with poor indicators and metrics. Cascades compounded into major negative impacts in the downstream of models like costly iterations, discarding projects, and harm to communities. Cascades were largely avoidable through intentional practices.

本文中，我们定义并识别了数据级联：从数据问题导致负面的下游效果的复合事件，随着事件导致了技术债务。在我们的研究中，数据级联是广泛存在的：92%的AI实践者在给定的项目中体验过一次或多次，45.3%体验过两次或多次级联。数据级联通常是应用传统AI实践的结果，其中对数据质量是低估的。比如，眼部疾病的检测模型，在无噪声的训练数据中训练的，可以得到很高的模型性能，在生产中，图像中有很小的尘埃斑点，就不能预测出准确的疾病状态。数据级联是不透明的，延迟出现的，指标和度量都很差。级联复合成下游模型的主要负作用，如昂贵的迭代，抛弃工程，对团体有害。级联通过刻意的联系，大致是可以避免的。

The high prevalence of fairly severe data cascades point to a larger problem of broken data practices, methodologies, and incentives in the field of AI. Although the AI/ML practitioners in our study were attuned to the importance of data quality and displayed deep moral commitment to vulnerable groups, data cascades were disturbingly prevalent even in the high stakes domains we studied. Additionally, our results point to serious gaps in what AI practitioners were trained and equipped to handle, in the form of tensions in working with field partners and application-domain experts, and in understanding human impacts of models—a serious problem as AI developers seek to deploy in domains where governments, civil society, and policy makers have historically struggled to respond. The prevalence of data cascades point to the contours of a larger problem: residual conventions and perceptions in AI/ML drawn from worlds of ‘big data’—of abundant, expendable digital resources and worlds in which one user has one account [108]; of model valourisation [125]; of moving fast to proof-of-concept [8]; and of viewing data as grunt work in ML workflows [111]. Taken together, our research underscores the need for data excellence in building AI systems, a shift to proactively considering care, sanctity, and diligence in data as valuable contributions in the AI ecosystem. Any solution needs to take into account social, technical, and structural aspects of the AI  ecosystem, which we discuss in our paper.

相对严重的数据级联的广泛性，指的是破碎数据练习，方法论和AI领域中的激励的更大问题。虽然在我们的研究中AI/ML实践者熟悉数据质量的重要性，对脆弱团体展现出了很深的道德承诺，数据级联在我们研究的高风险领域中是令人不安的广泛存在的。另外，我们的结果指出，在AI实践者训练和装备去处理的问题中，存在很大的差距，其形式是与领域伙伴和应用领域的专家的矛盾，以及在理解人类对模型的影响中，这是一个严重的问题，因为AI开发者要部署的领域，是政府，社会和政策制定者在历史中挣扎着回应的领域。数据级联的广泛性指出更大的问题的轮廓：从大数据的世界中得到的AI/ML的残余惯例和感知，其中有大量可消耗的数字资源，在这个世界中，每个用户都有一个账户；概念的快速验证；将数据视为ML工作流中的麻烦的工作。这些一起，我们的研究对在构建AI系统中对数据杰出的需求打了很低的分，应当将数据在AI生态系统的贡献视为非常珍贵。任何解决方案都需要将AI生态系统的社会方面，技术方面和结构方面都纳入考虑，我们在文章中进行讨论。

Our paper makes three main contributions: 我们的文章有三个主要贡献：

(1) Conceptualising and documenting data cascades, their characteristics, and impact on the end-to-end AI lifecycle, drawn from an empirical study of data practices of international AI practitioners in high-stakes domains. 提出并记录了数据级联的概念，其特征，以及对端到端AI生命循环的影响，这是国际AI实践者在高风险领域中的经验研究的结果；

(2) Empirically derived awareness for the need of urgent structural change in AI research and development to incentivise care in data excellence, through our case study of high-stakes AI. 我们从经验中推导得到，需要对AI研究和开发中的结构进行急切的变化，对数据的重要性要提出关注，这是我们在高风险AI的研究结果。

(3) Implications for HCI: we highlight an under-explored but significant new research path for the field in creating interfaces, processes, and policy for data excellence in AI. 对HCI的影响：我们强调了探索不足的，但是是显著的新研究路径，对AI中的数据重要性创建界面，过程和政策。

## 2. RELATED WORK

### 2.1 Data in HCI

Prior research in HCI has drawn particular attention to work practices and challenges faced by practitioners in working with data [48, 65, 86, 93, 96]. Feinberg describes data as a design material and our role as designers of data, not its appropriators [35]. Researchers have also studied the ways in which data is rarely used as given, and often needs to be created or handcrafted using intricate transformation practices [67, 96].

HCI中的之前研究已经吸引了特别的关注，对于在数据中工作的实践者所面临的工作实践和挑战的关注。Feinberg将数据描述为设计材料，而我们的角色是数据的设计者，而不是其占有者。研究者还研究了数据的使用方式，很少是直接给定使用，而是需要用复杂的变换实践来进行创建或改动。

An emerging stream of research in HCI and CSCW focuses on the work and collaboration practices of data scientists [66, 77, 94, 127]. Muller et al. extend and outline five approaches of data scientists to perform analyses: discovery, capture, design, curation, and creation of data [86]. Koesten et al. identify a need to understand the ways in which collaboration occurs for data on a spectrum—from creating and sharing inside and outside the organisation or reusing another person’s data with limited interaction with the creator [69]. Practitioners have been shown to collaborate much less around datasets, relative to collaboration around code [127]. Data documentation, which is a crucial aspect of facilitating collaboration, is well studied in the database and data management community [19, 23]. However, documentation of data suffers from a lack of standards and conventions within the ML community [40].

在HCI和CSCW的研究中的出现的潮流，关注的是数据科学家的工作和合作实践。Muller等列出了数据科学家进行分析的5种方式：数据的发现，捕获，设计，维护和创造。Koesten等发现了理解数据中的合作的方式，从组织内外的创建和共享，或重用另外一个人的数据，而与创建者的互动很有限。实践者在数据集方面的合作甚少，与在代码中的合作相对而言。数据记录，这是促进合作的一个重要方面，在数据库和数据管理中研究的很多。但是，数据的记录在ML团体中缺少标准和惯例。

Prior work in HCI and CSCW does not appear to explicitly focus on data practices in high-stakes domains, which are proliferating, and are marked by complex challenges of data scarcity, downstream impacts, and specialised inter-disciplinary knowledge for working with and understanding data (e.g., what a fractured bone looks like in an X-Ray might be beyond an AI practitioner’s area of expertise). Several studies have focused on data practices of data scientists; our research extends the focus on data to ML practitioners, including
engineers, researchers, and academics who build and deploy AI/ML technologies. Prior research has focused primarily on Western populations, that often have fewer resource constraints, and greater acceptance and understanding of AI in their communities. Our research presents an international analysis of data-related practices and issues in India, East and West African countries, and the US.

之前在HCI和CSCW中的工作，并没有特别关注在高风险领域中的数据实践，这是在逐渐增加的，由于数据稀少，下游的影响，和需要专业领域的知识才能理解数据，所以通常认为是复杂的挑战（如，骨折在X射线片中应当是什么样子的，这是AI实践者的知识范畴以外的）。几个研究聚焦在数据科学家的数据实践；我们的研究将焦点从数据拓展到ML实践者，包括工程师，研究人员，和学者，他们构建和部署了AI/ML技术。之前的研究主要关注西方的群体，通常有更少的资源限制，在其团体中对AI有更好的接受度和理解。我们的研究提出了对数据相关实践和问题的国际化分析，包括印度，东非，西非和美国。

### 2.2 Politics of data

There is substantial work in HCI and STS to establish that data is never ‘raw’ [41], but rather is shaped through the practices of collecting, curating and sensemaking, and thus is inherently sociopolitical in nature. Through their study of public health data, Pine and Liboiron [99] demonstrate how data collection is shaped by values and decisions about “what is counted and what is excluded, and what is considered the best unit of measurement.” Vertisi and Dourish [123] examine data in an interactional context and argue for considering the contexts of production in data economies, alongside use and exchange to clarify the ways in which data acquires meaning. Taylor et al. [118] drew attention to this need in their research on considering the physical and social geography in which data, people, and things are situated, and to represent the rich geo-tapestry within which data is entangled.

在HCI和STS中，有很基础的工作确立了，数据从来不是原始的，而是在收集、维护和创造意义的过程中形成的，因此在本质上就是社会和政治的。通过他们对公开健康数据的研究，Pine和Liboiron展示了，数据收集是怎样受到价值和决定形成的，比如，什么是有用的，什么是要被排除的，什么是度量的最佳单位。Vertisi和Dourish在互动的上下文中研究了数据，认为在数据经济考虑产生的上下文，与使用和交换一起，以阐明数据获得意义的方式。Taylor等对这种需求产生了注意力，在其研究中考虑物理和社会地理，其中数据，人和事物是联系在一起的，而且表示这些纠缠的数据为丰富的地理壁毯。

Critical data studies researchers have demonstrated longstanding interest in the ‘discretionary’ [95] practices shaping data-driven systems and how they are designed and used [6, 16, 33], and the ways in which data science teams are constituted [106]. Passi and Jackson [93] describe how data work is often invisibilized through a focus on rules, arguing that empirical challenges render invisible the efforts to make algorithms work with data. This makes it difficult to account for the situated and creative decisions made by data analysts, and leaving behind a stripped down notion of ‘data analytics’. Passi and Sengers [95] turn their attention to the negotiations in designing data science systems, on how a system should work and is evaluated.

关键的数据研究研究者已经表明，对随意的实践形成了数据驱动的系统，以及他们是怎样设计使用的，以及数据科学团队是怎样构成的，有很长久的兴趣。Passi和Jackson描述了数据工作通常是不可见的，因为会关注规则，认为经验挑战使得这些努力变得不可见，以使算法使用数据进行工作。这就使其要考虑数据分析师的有创意的决定非常困难，对数据分析的工作基本不会有感觉。Passi和Sengers将其注意力转到在设计数据科学系统的谈判中，以及系统是怎样工作和评估的。

Beyond data scientists, there are many roles in the process of preparing, curating, and nurturing data, which are often under-paid and over-utililized. Many researchers have pointed to the under-valued human labour that powers AI models (e.g., heteromation [34], fauxtomation [117], and “menial” vs. “innovative” work distinctions [56]). Møller et al. [85] describe the crucial data work through a framework of meaningful registration, digital organizing, and concern for ethics. They discuss how the data work of clerical hospital workers is complex, skillful, and effortful [85]. However, data work has been shown to be invisibilized among Mechanical Turkers by Martin et al. [79], and among frontline health workers in India by Ismail and Kumar [58]. Through a post-colonial feminist perspective, Ismail and Kumar [58] highlight how frontline health workers in India navigate the multiple demands placed on them, and how their data work is severely under-compensated. Our research extends discourses on how data workers play a critical role in creating and maintaining AI systems, and the ways in which their work can have downstream impacts.

在数据科学家之外，在准备，维护和培育数据的过程中，有很多角色，通常待遇很少，过度利用。很多研究者指出，为AI模型赋能的被低估的人力。Møller等描述了关键的数据工作，包括有意义的配准，数字组织，考虑道德等的框架。他们讨论了牧师医院工作者的数据工作是复杂的，需要技能的，需要努力的。但是，数据工作在Mechanical Turkers中，是不可见的，是在印度前线的健康工作者中的。从后殖民地女权主义者的角度看，Ismail等强调了印度的前线健康工作者是怎样应对交给他们的多个要求，以及他们的数据工作是严重欠补偿的。我们的研究拓展了数据工作者怎样在创建和维护AI系统中扮演关键的角色，以及其工作是怎样可以有下游的影响。

### 2.3 Data quality interventions 数据质量干预

Real-world datasets are often ‘dirty’ and come with a variety of data quality problems [1]. However, data quality is crucial to ensure that the ML system using the data can accurately represent and predict the phenomenon it is claiming to measure. A well-established, and steadily growing, body of work focuses on understanding and improving data quality to avoid the garbage in, garbage out problem [45, 103].

Kandel et al. reveal that practitioners consider data wrangling tedious and time-consuming [62]. Thus, improving quality through transformations [52] and building human-in-the-loop data cleaning systems[61] are well-studied research areas in the data management community. Practitioners often work with a set of assumptions about their data during analysis and visualisation, which guides their data transformations [62]. Interactive data cleaning focuses on making this process easier, because data transformations can be difficult to specify and reuse across multiple tasks [61, 72, 102]. For instance, Wrangler suggests potentially relevant transforms, and maintains a history of transformation scripts to support review and refinement [61]. Data cleaning and wrangling systems address data quality issues by using integrity constraints [27], type inference [36], schema matching [43], outlier detection [51] and more. 

Researchers have created several tools to support the creation of ML ‘pipelines’ and make these workflows manageable [21, 54, 70, 72, 76]. Similar to Code Linters common in traditional SE, Data Linter is a tool to inspect ML datasets, identify potential data issues and suggest transformations to fix these issues [54]. Breck et al. created a data validation system to detect anomalies in Machine learning pipelines [21]. Other frameworks to discover data bugs and clean data include ActiveClean and BoostClean [70, 72]. Such interventions highlight the importance of catching data errors using mechanisms specific to data validation, instead of using model performance as a proxy for data quality [120]. In addition to this, it is crucial to test and monitor data as much as we focus on the testing of code. Breck et al. provided a set of 28 actionable tests for features, data and models [21]. There is extensive literature on ML testing for detecting differences between the actual and expected behaviour of ML pipelines; for a survey, see [129]. Researchers in the field of HCI and HCOMP have demonstrated a longstanding interest in making use of crowdsourcing to generate ML data [25, 128], to support creation of better task designs for raters [59], compute interrater reliability, design incentives [50], and improve the quality of crowdsourced data [30], though these areas are less well known in the ML community [122].

Prior research on developing data quality systems has largely focused on data cleaning and wrangling. However, high-stakes domains extend both, into upstream (data creation) and downstream (live data after deployment)—our research extends this growing body of work by focusing on the end-to-end lifecycle of data in high-stakes domains. For example, viewing data as a dynamic entity points us to drifts and hidden skews5. Prior work on data systems appears to be built for intra-organisational AI development. Our research extends current discourses to high-stakes AI which typically involve cross-organisational and inter-disciplinary work; for example, dataset definition and labelling accuracy all depend on application-domain expertise that comes from collaboration with field partners and domain experts.

### 2.4 Machine Learning in production

## 3. METHODOLOGY

## 4. FINDINGS

