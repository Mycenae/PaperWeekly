# Histograms of Oriented Gradients for Human Detection

Navneet Dalal and Bill Triggs INRIA, France

## 0. Abstract

We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.

我们研究了用于稳健视觉目标识别的特征集问题，采用了基于线性SVM的人体检测作为测试案例。在回顾了已有的基于边缘和梯度的描述子之后，我们通过试验证明了，有向梯度直方图(HOG)描述子在人体检测上明显超过了现有的特征集。我们研究了每个阶段的计算对性能的影响，得出结论说，细节梯度，精细的方向binning，相对粗糙的空间binning，和重叠描述子的高质量的局部对比度归一化，对很好的结果都是很重要的。新方法在MIT行人数据集上得到了几乎完美的区分，所以我们引入了一个更加有挑战性的数据集，包含了超过1800幅标注的人类图像，姿态变化和背景变化都很多。

## 1. Introduction

Detecting humans in images is a challenging task owing to their variable appearance and the wide range of poses that they can adopt. The first need is a robust feature set that allows the human form to be discriminated cleanly, even in cluttered backgrounds under difficult illumination. We study the issue of feature sets for human detection, showing that locally normalized Histogram of Oriented Gradient (HOG) descriptors provide excellent performance relative to other existing feature sets including wavelets [17,22]. The proposed descriptors are reminiscent of edge orientation histograms [4,5], SIFT descriptors [12] and shape contexts [1], but they are computed on a dense grid of uniformly spaced cells and they use overlapping local contrast normalizations for improved performance. We make a detailed study of the effects of various implementation choices on detector performance, taking “pedestrian detection” (the detection of mostly visible people in more or less upright poses) as a test case. For simplicity and speed, we use linear SVM as a baseline classifier throughout the study. The new detectors give essentially perfect results on the MIT pedestrian test set [18,17], so we have created a more challenging set containing over 1800 pedestrian images with a large range of poses and backgrounds. Ongoing work suggests that our feature set performs equally well for other shape-based object classes.

图像中的人体检测是一个很有挑战的任务，因为外观变化很多，而且人的姿态也非常多样。首先需要的是一个稳健的特征集，即使在很难的光照中在嘈杂的背景中，可以很干净的区分出人的外形。我们研究了人形检测的特征集问题，表明相对于其他已有的特征集，包括小波，局部归一化的有向方向直方图(HOG)描述子可以给出优异的性能。提出的描述子让人想起边缘方向直方图，SIFT描述子和形状上下文，但它们是在均匀间隔的单元的密集网格上计算的，使用叠加的局部对比度归一化来进行性能改进。我们详细研究了各种实现选择对检测器性能的影响，并选择“行人检测”（在基本上竖直姿态的情况下，检测多数可见的人）作为测试案例。为了简化和速度，我们在研究中使用线性SVM作为基准分类器。新检测器在MIT行人测试集上给出了非常完美的结果，所以我们创建了一个更有挑战性的集合，包含超过1800张行人图像，其姿态和背景变化非常大。正在进行的工作说明，我们的特征集对于其他基于形状的目标类别的表现同样的好。

We briefly discuss previous work on human detection in §2, give an overview of our method §3, describe our data sets in §4 and give a detailed description and experimental evaluation of each stage of the process in §5–6. The main conclusions are summarized in §7.

我们在第2部分简要讨论了之前的工作，在第3部分给出了我们方法的概览，第4部分讨论了数据集，在第5-6部分给出了每个阶段的详细描述和试验评估。第7部分给出了主要结论。

## 2. Previous Work

There is an extensive literature on object detection, but here we mention just a few relevant papers on human detection [18,17,22,16,20]. See [6] for a survey. Papageorgiou et al [18] describe a pedestrian detector based on a polynomial SVM using rectified Haar wavelets as input descriptors, with a parts (subwindow) based variant in [17]. Depoortere et al give an optimized version of this [2]. Gavrila & Philomen [8] take a more direct approach, extracting edge images and matching them to a set of learned exemplars using chamfer distance. This has been used in a practical real-time pedestrian detection system [7]. Viola et al [22] build an efficient moving person detector, using AdaBoost to train a chain of progressively more complex region rejection rules based on Haar-like wavelets and space-time differences. Ronfard et al [19] build an articulated body detector by incorporating SVM based limb classifiers over 1st and 2nd order Gaussian filters in a dynamic programming framework similar to those of Felzenszwalb & Huttenlocher [3] and Ioffe & Forsyth [9]. Mikolajczyk et al [16] use combinations of orientation-position histograms with binary-thresholded gradient magnitudes to build a parts based method containing detectors for faces, heads, and front and side profiles of upper and lower body parts. In contrast, our detector uses a simpler architecture with a single detection window, but appears to give significantly higher performance on pedestrian images.

目标检测有很多文献，这里我们只提到了一些在人体检测的相关工作。[6]是一个综述。[18]中有一个行人检测器，基于多项式SVM，使用整流Haar小波作为输入描述子，[17]中是一个基于部位（子窗口）的变体。[2]中是一个优化的版本。[8]给出了一个更加直接的方法，提取边缘图像，并将其与学习到的样本集利用chamfer距离进行匹配，这在实际的实时行人检测系统中进行了使用[7]。[22]构建了一个高效的滑动人体检测器，使用AdaBoost训练了逐渐更复杂的区域拒绝规则链，基于Haar类的小波和时空差异。[19]构建了一个铰接人体检测器，将基于SVM的肢体分类器结合到一起。[16]使用方向-位置直方图与二值阈值梯度幅度的组合，构建了一个基于部位的方法，包含对人脸、头和上肢和下肢的侧位图的检测器。对比起来，我们的检测器使用了更简单的架构，只有一个检测窗口，在行人图像上给出了明显更好的性能。

## 3.  Overview of the Method

This section gives an overview of our feature extraction chain, which is summarized in fig. 1. Implementation details are postponed until §6. The method is based on evaluating well-normalized local histograms of image gradient orientations in a dense grid. Similar features have seen increasing use over the past decade [4,5,12,15]. The basic idea is that local object appearance and shape can often be characterized rather well by the distribution of local intensity gradients or edge directions, even without precise knowledge of the corresponding gradient or edge positions. In practice this is implemented by dividing the image window into small spatial regions (“cells”), for each cell accumulating a local 1-D histogram of gradient directions or edge orientations over the pixels of the cell. The combined histogram entries form the representation. For better invariance to illumination, shadowing, etc., it is also useful to contrast-normalize the local responses before using them. This can be done by accumulating a measure of local histogram “energy” over somewhat larger spatial regions (“blocks”) and using the results to normalize all of the cells in the block. We will refer to the normalized descriptor blocks as Histogram of Oriented Gradient (HOG) descriptors. Tiling the detection window with a dense (in fact, overlapping) grid of HOG descriptors and using the combined feature vector in a conventional SVM based window classifier gives our human detection chain (see fig. 1).

本节给出了我们特征提取链的概览，如图1所示。实现细节在第6部分给出。本方法是基于在密集网格中评估图像梯度方向的归一化过的局部直方图。类似的特征在过去十年用的越来越多。其基础思想是，局部目标外观和形状通常可以用局部亮度梯度或边缘方向的分布进行很好的表征，甚至不需要对应的梯度或边缘位置的精确知识。在实践中，我们将图像窗口分成小的空间区域（单元cell），对每个单元聚积一个局部1D梯度方向或边缘方向直方图。结合的直方图条目形成了整体表示。为了对光照，阴影等有更好的不变性，在对局部响应使用前进行对比度归一化，也是很有用的。通过在更大的空间区域(blocks)中累积局部直方图的能量的度量，并使用这个结果对block中的所有cells进行归一化，就可以实现这个效果。我们称归一化的描述子block为HOG描述子。将检测窗口与HOG描述子的密集网格堆叠在一起，使用结合的特征向量进行传统的基于SVM的窗口分类，这就给出了我们的人体检测链（见图1）。

The use of orientation histograms has many precursors [13,4,5], but it only reached maturity when combined with local spatial histogramming and normalization in Lowe’s Scale Invariant Feature Transformation (SIFT) approach to wide baseline image matching [12], in which it provides the underlying image patch descriptor for matching scale-invariant keypoints. SIFT-style approaches perform remarkably well in this application [12,14]. The Shape Context work [1] studied alternative cell and block shapes, albeit initially using only edge pixel counts without the orientation histogramming that makes the representation so effective. The success of these sparse feature based representations has somewhat overshadowed the power and simplicity of HOG’s as dense image descriptors. We hope that our study will help to rectify this. In particular, our informal experiments suggest that even the best current keypoint based approaches are likely to have false positive rates at least 1–2 orders of magnitude higher than our dense grid approach for human detection, mainly because none of the keypoint detectors that we are aware of detect human body structures reliably.

有很多以前的工作也使用方向直方图，但只有在SIFT中与局部空间直方图和归一化结合到一起，才达到成熟，拓宽了图像匹配的基准，给出了图像块描述子以匹配尺度不变的关键点。SIFT式的方法在这种应用中表现非常好。Shape Context [1]研究了其他的cell和block形状，即开始只使用边缘像素数量，没有方向直方图，使其表示非常有效。这种基于稀疏特征的表示的成功，在某种程度上使得HOG这种密集图像描述子的能量和简洁性没那么明显。我们希望，我们的研究可以纠正这一点。特别是，我们的非正式试验表明，即使是最好的目前的基于关键点的方法，其在人体检测上的假阳性率也很可能比我们的密集网格方法的要高1-2个数量级，主要是因为，我们所知道的这些基于关键点的检测器都不能很可靠的检测人体结构。

The HOG/SIFT representation has several advantages. It captures edge or gradient structure that is very characteristic of local shape, and it does so in a local representation with an easily controllable degree of invariance to local geometric and photometric transformations: translations or rotations make little difference if they are much smaller than the local spatial or orientation bin size. For human detection, rather coarse spatial sampling, fine orientation sampling and strong local photometric normalization turns out to be the best strategy, presumably because it permits limbs and body segments to change appearance and move from side to side quite a lot provided that they maintain a roughly upright orientation.

HOG/SIFT表示有几个优势。其捕获的边缘或梯度结构，可以很好的表示局部形状的特征，用局部表示进行，对局部几何和亮度变换的不变性可以很容易的控制：如果比局部空间或方向bin的大小小很多，平移或旋转几乎没有差别。对于人体检测，非常粗糙的空间采样，精细的方向采样和很强的局部亮度归一化，是最好的策略，这是因为只要保持大致竖直的方向，这可以允许四肢和身体改变外观，从一边移到另一边。

## 4 Data Sets and Methodology

**Datasets**. We tested our detector on two different data sets. The first is the well-established MIT pedestrian database [18], containing 509 training and 200 test images of pedestrians in city scenes (plus left-right reflections of these). It contains only front or back views with a relatively limited range of poses. Our best detectors give essentially perfect results on this data set, so we produced a new and significantly more challenging data set, ‘INRIA’, containing 1805 64×128 images of humans cropped from a varied set of personal photos. Fig. 2 shows some samples. The people are usually standing, but appear in any orientation and against a wide variety of background image including crowds. Many are bystanders taken from the image backgrounds, so there is no particular bias on their pose. The database is available from http://lear.inrialpes.fr/data for research purposes.

**数据集**。我们在两个不同的数据集上测试了我们的检测器。第一个是成熟的MIT行人数据集，包含509张训练图像，200张测试图像，都是城市场景的行人图像，只包含前视角或后视角，姿态变化相对较少。我们最好的检测器在这个数据集上给出了基本完美的结果，所以我们提出了一个新的明显更有挑战的新数据集，INRIA，包含了1805张64×128的图像，是从很多个人照片中剪切出来的人类。图2给出了几个例子。其中的人通常是站着的，但方向各异，背景各异，包含人群。很多是图像背景中的旁观者，所以对于姿态没有很强的偏好。数据集已经公开。


**Methodology**. We selected 1239 of the images as positive training examples, together with their left-right reflections (2478 images in all). A fixed set of 12180 patches sampled randomly from 1218 person-free training photos provided the initial negative set. For each detector and parameter combination a preliminary detector is trained and the 1218 negative training photos are searched exhaustively for false positives (‘hard examples’). The method is then re-trained using this augmented set (initial 12180 + hard examples) to produce the final detector. The set of hard examples is subsampled if necessary, so that the descriptors of the final training set fit into 1.7 Gb of RAM for SVM training. This retraining process significantly improves the performance of each detector (by 5% at 10^−4 False Positives Per Window tested (FPPW) for our default detector), but additional rounds of retraining make little difference so we do not use them.

**方法论**。我们选择了1239张图像作为正训练样本，将其进行了左右翻转合并到了一起，一共2478幅图像。从1218张没有人体的训练图像中随机采样了12180个图像块，这个固定集合是初始的负样本集。对每个检测器和参数组合，都训练了一个初级检测器，对这1218幅负训练图像进行穷举式搜索，得到假阳性样本（难分样本）。使用扩充集合（初始的12180+难分样本）再进行重新训练，以得到最终的检测器。如果有必要的话，对难分样本进行下采样，这样最终的训练集的描述子在1.7Gb内存以内，以进行SVM训练。重新训练的过程显著改进了每个检测器的性能，但更多的重新训练其差异不大，所以我们就没有使用。

To quantify detector performance we plot Detection Error Tradeoff (DET) curves on a log-log scale, i.e. miss rate (1−Recall or FalseNeg/TruePos+FalseNeg) versus FPPW. Lower values are better. DET plots are used extensively in speech and in NIST evaluations. They present the same information as Receiver Operating Characteristics (ROC’s) but allow small probabilities to be distinguished more easily. We will often use miss rate at 10^−4FPPW as a reference point for results. This is arbitrary but no more so than, e.g. Area Under ROC. In a multiscale detector it corresponds to a raw error rate of about 0.8 false positives per 640×480 image tested. (The full detector has an even lower false positive rate owing to non-maximum suppression). Our DET curves are usually quite shallow so even very small improvements in miss rate are equivalent to large gains in FPPW at constant miss rate. For example, for our default detector at 1e-4 FPPW, every 1% absolute (9% relative) reduction in miss rate is equivalent to reducing the FPPW at constant miss rate by a factor of 1.57.

为量化检测器的性能，我们以log-log尺度来画出DET曲线。DET曲线在语音和NIST评估中大量使用。这与ROC曲线是一样的信息，但可以使小概率更好的区分识别。我们通常使用10^−4FPPW的错误率作为参考点得到结果。在一个多尺度检测器中，其对应着原始错误率为，每个640×480测试的图像中，有0.8个假阳性。（完整的检测器的假阳性率会更低，因为有nms）。

## 5 Overview of Results

Before presenting our detailed implementation and performance analysis, we compare the overall performance of our final HOG detectors with that of some other existing methods. Detectors based on rectangular (R-HOG) or circular log-polar (C-HOG) blocks and linear or kernel SVM are compared with our implementations of the Haar wavelet, PCA-SIFT, and shape context approaches. Briefly, these approaches are as follows:

在给出详细实现和性能分析之前，我们将我们最终的HOG检测器与已经存在的其他方法进行了总体性能比较。基于矩形R-HOG或圆形C-HOG block和线性SVM或核SVM的检测器，与我们实现的Haar小波，PCA-SIFT和shape context方法进行了比较。简要来说，这些方法如下所述：

**Generalized Haar Wavelets**. This is an extended set of oriented Haar-like wavelets similar to (but better than) that used in [17]. The features are rectified responses from 9×9 and 12×12 oriented 1st and 2nd derivative box filters at 45◦ intervals and the corresponding 2nd derivative xy filter. 这是有向Haar类小波的拓展集合，与[17]中所使用的类似，但是要更好。

**PCA-SIFT**. These descriptors are based on projecting gradient images onto a basis learned from training images using PCA [11]. Ke & Sukthankar found that they outperformed SIFT for keypoint based matching, but this is controversial [14]. Our implementation uses 16×16 blocks with the same derivative scale, overlap, etc., as our HOG descriptors. The PCA basis is calculated using the positive training images. 这些描述子是基于，使用PCA从训练图像中学习到一个基底，将梯度图像投影到这个基底上。Ke & Sukthankar发现，对于基于关键点的匹配，这超过了SIFT，但这是有争议的[14]。我们的实现使用了16×16的blocks，导数尺度，overlap等与我们的HOG描述子相同。PCA基底是用正训练图像计算的。

**Shape Contexts**. The original Shape Contexts [1] used binary edge-presence voting into log-polar spaced bins, irrespective of edge orientation. We simulate this using our C-HOG descriptor (see below) with just 1 orientation bin. 16 angular and 3 radial intervals with inner radius 2 pixels and outer radius 8 pixels gave the best results. Both gradient-strength and edge-presence based voting were tested, with the edge threshold chosen automatically to maximize detection performance (the values selected were somewhat variable, in the region of 20–50 graylevels). 原始的Shape Contexts [1]使用二值边缘投票到log-polar间距的bins，而不论边缘方向是什么。我们用C-HOG描述子对其进行模拟，只用了1个方向bin。给出最好结果的是，16个角方向和3个径向的间隔，内半径2像素，外半径8个像素。基于梯度强度和边缘存在的投票都进行了测试，边缘阈值可以自动选择，以最大化检测性能（选择的值是可以变化的，在20-50灰度值的范围内）。

**Results**. Fig. 3 shows the performance of the various detectors on the MIT and INRIA data sets. The HOG-based detectors greatly outperform the wavelet, PCA-SIFT and Shape Context ones, giving near-perfect separation on the MIT test set and at least an order of magnitude reduction in FPPW on the INRIA one. Our Haar-like wavelets outperform MIT wavelets because we also use 2nd order derivatives and contrast normalize the output vector. Fig. 3(a) also shows MIT’s best parts based and monolithic detectors (the points are interpolated from [17]), however beware that an exact comparison is not possible as we do not know how the database in [17] was divided into training and test parts and the negative images used are not available. The performances of the final rectangular (R-HOG) and circular (C-HOG) detectors are very similar, with C-HOG having the slight edge. Augmenting R-HOG with primitive bar detectors (oriented 2nd derivatives – ‘R2-HOG’) doubles the feature dimension but further improves the performance (by 2% at 10^−4 FPPW). Replacing the linear SVM with a Gaussian kernel one improves performance by about 3% at 10^−4 FPPW, at the cost of much higher run times. Using binary edge voting (EC-HOG) instead of gradient magnitude weighted voting (C-HOG) decreases performance by 5% at 10−4 FPPW, while omitting orientation information decreases it by much more, even if additional spatial or radial bins are added (by 33% at 10^−4 FPPW, for both edges (E-ShapeC) and gradients (G-ShapeC)). PCA-SIFT also performs poorly. One reason is that, in comparison to [11], many more (80 of 512) principal vectors have to be retained to capture the same proportion of the variance. This may be because the spatial registration is weaker when there is no keypoint detector.

图3给出了各种检测器在MIT和INRIA数据集上的性能比较。基于HOG的检测器极大的超过了小波，PCA-SIFT和shape context检测器，在MIT测试集上给出了几乎完美的结果，在INRIA数据集上FPPW至少降低了一个数量级。我们的类Haar的小波超过了MIT小波，因为我们还使用了输出向量的二阶导数和对比度归一化。图3a还展示了MIT最好的基于部位的和整体式检测器，但是准确的比较是不可能的，因为我们不知道[17]中的数据集是怎样分成训练集和测试集的，使用的负样本图像也不可用。最终的R-HOG和C-HOG检测器的性能非常类似，C-HOG略低一些。

## 6. Implementation and Performance Study

We now give details of our HOG implementations and systematically study the effects of the various choices on detector performance. Throughout this section we refer results to our default detector which has the following properties, described below: RGB colour space with no gamma correction; [−1, 0, 1] gradient filter with no smoothing; linear gradient voting into 9 orientation bins in 0◦–180◦; 16×16 pixel blocks of four 8×8 pixel cells; Gaussian spatial window with σ = 8 pixel; L2-Hys (Lowe-style clipped L2 norm) block normalization; block spacing stride of 8 pixels (hence 4-fold coverage of each cell); 64×128 detection window; linear SVM classifier.

我们现在给出HOG实现的细节，系统的研究各种选项对检测器性能的影响。本节中，我们的默认检测器有以下性质：RGB色彩空间没有gamma校正；梯度滤波器为[-1, 0, 1]，没有平滑；线性梯度投票到0◦–180◦的9个方向bins；16×16像素的blocks，4个8x8像素的cells；高斯空间窗口，σ = 8；L2-Hys block归一化；block间距步长8个像素；64x128检测窗口；线性SVM分类器。

Fig. 4 summarizes the effects of the various HOG parameters on overall detection performance. These will be examined in detail below. The main conclusions are that for good performance, one should use fine scale derivatives (essentially no smoothing), many orientation bins, and moderately sized, strongly normalized, overlapping descriptor blocks.

图4总结了各种HOG参数对总体检测性能的影响。这会进行详细研究。主要的结论是，要得到好的性能，应当使用精细尺度的导数（不需要平滑），很多方向bins，大小适中，很强归一化的，重叠的描述子blocks。

### 6.1 Gamma/Colour Normalization

We evaluated several input pixel representations including grayscale, RGB and LAB colour spaces optionally with power law (gamma) equalization. These normalizations have only a modest effect on performance, perhaps because the subsequent descriptor normalization achieves similar results. We do use colour information when available. RGB and LAB colour spaces give comparable results, but restricting to grayscale reduces performance by 1.5% at 10^−4 FPPW. Square root gamma compression of each colour channel improves performance at low FPPW (by 1% at 10^−4 FPPW) but log compression is too strong and worsens it by 2% at 10^−4 FPPW.

我们评估了几种输入像素表示，包括灰度，RGB和LAB色彩空间，可能带有power law(gamma)均衡。这些归一化对性能的影响不大，可能因为后续的描述子归一化有类似的效果。在可用的时候，我们会使用色彩信息。RGB和LAB会给出类似的结果，但只使用灰度信息，性能会下降1.5% at 10^−4 FPPW。每个色彩通道的平方根gamma压缩，在低FPPW时会改进性能(by 1% at 10^−4 FPPW)，但log压缩太强了会降低性能，在10^-4 FPPW时恶化2%。

### 6.2 Gradient Computation

Detector performance is sensitive to the way in which gradients are computed, but the simplest scheme turns out to be the best. We tested gradients computed using Gaussian smoothing followed by one of several discrete derivative masks. Several smoothing scales were tested including σ=0 (none). Masks tested included various 1-D point derivatives (uncentred [−1, 1], centred [−1, 0, 1] and cubic-corrected [1, −8, 0, 8, −1]) as well as 3×3 Sobel masks and 2×2 diagonal ones [0, 1; −1 0], [−1 0; 0 1] (the most compact centred 2-D derivative masks). Simple 1-D [−1, 0, 1] masks at σ=0 work best. Using larger masks always seems to decrease performance, and smoothing damages it significantly: for Gaussian derivatives, moving from σ=0 to σ=2 reduces the recall rate from 89% to 80% at 10^−4 FPPW. At σ=0, cubic corrected 1-D width 5 filters are about 1% worse than [−1, 0, 1] at 10−4 FPPW, while the 2×2 diagonal masks are 1.5% worse. Using uncentred [−1, 1] derivative masks also decreases performance (by 1.5% at 10−4 FPPW), presumably because orientation estimation suffers as a result of the x and y filters being based at different centres.

检测器性能对于梯度计算的方式是敏感的，但最简单的计算方法结果是最好的。我们测试了使用高斯平滑后采用几种离散导数掩模的梯度计算方法。测试了几个平滑尺度，包括σ=0，即没有平滑。测试的掩模包括，各种1D点微分（非中心的[-1, 1]，中心的[-1, 0, 1]，和三次修正的[1, -8, 0, 8, -1]），和3x3的sobel掩模，和2x2的对角线掩模[0, 1; -1, 0]，[-1, 0; 0, 1]（最紧凑的中心2D微分掩模）。简单的1D掩模[-1, 0, 1]效果最好。使用更大的掩模似乎降低了性能，平滑则使性能明显下降：对于高斯导数，从σ=0到σ=2将召回率从89%降到了80%。在σ=0时，三次修正的1D宽5的滤波器比[-1, 0, 1]效果差了1%，而2x2对角掩模差了1.5%。使用非中心的[-1, 1]导数掩模也降低了1.5%的性能，可能是因为方向估计的结果在x和y滤波器在不同的中心的时候会变差。

For colour images, we calculate separate gradients for each colour channel, and take the one with the largest norm as the pixel’s gradient vector.

对于彩色图像，我们对每个色彩通道分别计算梯度，并取最大范数的作为像素的梯度向量。

### 6.3 Spatial / Orientation Binning

The next step is the fundamental nonlinearity of the descriptor. Each pixel calculates a weighted vote for an edge orientation histogram channel based on the orientation of the gradient element centred on it, and the votes are accumulated into orientation bins over local spatial regions that we call cells. Cells can be either rectangular or radial (log-polar sectors). The orientation bins are evenly spaced over 0◦–180◦ (“unsigned” gradient) or 0◦–360◦ (“signed” gradient). To reduce aliasing, votes are interpolated bilinearly between the neighbouring bin centres in both orientation and position. The vote is a function of the gradient magnitude at the pixel, either the magnitude itself, its square, its square root, or a clipped form of the magnitude representing soft presence/absence of an edge at the pixel. In practice, using the magnitude itself gives the best results. Taking the square root reduces performance slightly, while using binary edge presence voting decreases it significantly (by 5% at 10^−4 FPPW).

下一步是描述子的基础非线性。每个像素对一个边缘方向直方图通道，基于以其为中心的梯度元素的方向，计算一个加权投票，投票累积到局部空间区域，即cells中的方向bins。Cells可以是矩形的或径向的(log-polar sectors)。方向bins是在0◦–180◦中均匀间隔的(无符号梯度)，或0◦–360◦中均匀间隔的(有符号梯度)。为降低混淆，投票在相邻的bin中央之间，对方向和位置进行双线性插值。投票是在这个像素处的梯度幅度的函数，可以是幅度本身，其平方，其平方根，或其他函数。实践中，使用幅度本身给出最好的结果。采用平方根略微降低性能，使用二值边缘存在投票明显降低性能。

Fine orientation coding turns out to be essential for good performance, whereas (see below) spatial binning can be rather coarse. As fig. 4(b) shows, increasing the number of orientation bins improves performance significantly up to about 9 bins, but makes little difference beyond this. This is for bins spaced over 0◦–180◦, i.e. the ‘sign’ of the gradient is ignored. Including signed gradients (orientation range 0◦–360◦, as in the original SIFT descriptor) decreases the performance, even when the number of bins is also doubled to preserve the original orientation resolution. For humans, the wide range of clothing and background colours presumably makes the signs of contrasts uninformative. However note that including sign information does help substantially in some other object recognition tasks, e.g. cars, motorbikes.

精细的方向编码对于好的性能是最关键的，而空间binning可以很粗糙。如图4b所示，增加方向bins的数量明显改进性能，直到9 bins，更多的bins则没有多大差异。这是对于0◦–180◦范围内的bins，即梯度的符号被忽略了。包含梯度的符号则会降低性能，甚至在bins数量翻倍的情况下也是如此。对于人体，衣着和背景颜色的多样性，使对比度的符号没有什么信息。但是，包含符号信息在一些其他目标识别任务中会有很大帮助，如，车，摩托车。

### 6.4 Normalization and Descriptor Blocks

Gradient strengths vary over a wide range owing to local variations in illumination and foreground-background contrast, so effective local contrast normalization turns out to be essential for good performance. We evaluated a number of different normalization schemes. Most of them are based on grouping cells into larger spatial blocks and contrast normalizing each block separately. The final descriptor is then the vector of all components of the normalized cell responses from all of the blocks in the detection window. In fact, we typically overlap the blocks so that each scalar cell response contributes several components to the final descriptor vector, each normalized with respect to a different block. This may seem redundant but good normalization is critical and including overlap significantly improves the performance. Fig. 4(d) shows that performance increases by 4% at 10^−4 FPPW as we increase the overlap from none (stride 16) to 16-fold area / 4-fold linear coverage (stride 4).

梯度强度变化很大，这是因为光照和前景背景对比度的局部变化，所以有效的局部对比度归一化对于好的性能来说非常关键。我们评估了很多不同的归一化方案。多数是基于，将cells分组成更大的空间blocks，对每个block分别进行对比度归一化。最终的描述子是，检测窗口中的所有blocks的归一化cell响应的所有元素的向量。实际上，我们一般把blocks叠加起来，所以每个标量cell响应对最终的描述子向量贡献了几个元素，每个都对一个不同的block进行归一化。这看起来似乎是冗余的，但好的归一化是关键的，而且包括重叠会显著改进性能。图4d展示了在我们增加重叠，从没有(步长16)到16-fold区域/4-fold线性覆盖(步长4)时，在10^-4 FPPW上性能提升了4%。

We evaluated two classes of block geometries, square or rectangular ones partitioned into grids of square or rectangular spatial cells, and circular blocks partitioned into cells in log-polar fashion. We will refer to these two arrangements as R-HOG and C-HOG (for rectangular and circular HOG).

我们评估了两类block几何，方形或矩形的，分割成方形或矩形的空间cells的网格，和圆形的blocks，分割成log-polar式的cells。我们称这两种方案为R-HOG，和C-HOG。

**R-HOG**. R-HOG blocks have many similarities to SIFT descriptors [12] but they are used quite differently. They are computed in dense grids at a single scale without dominant orientation alignment and used as part of a larger code vector that implicitly encodes spatial position relative to the detection window, whereas SIFT’s are computed at a sparse set of scale-invariant key points, rotated to align their dominant orientations, and used individually. SIFT’s are optimized for sparse wide baseline matching, R-HOG’s for dense robust coding of spatial form. Other precursors include the edge orientation histograms of Freeman & Roth [4]. We usually use square R-HOG’s, i.e. ς×ς grids of η×η pixel cells each containing β orientation bins, where ς, η, β are parameters.

R-HOG和SIFT描述子有很多相似性，但在使用上有很多不同。他们在密集网格上进行单尺度计算，没有主要的方向对齐，用作更大的编码向量的一部分，隐式的编码了相对于检测窗口的空间位置，而SIFT计算的是一些尺度不变的关键点的稀疏集，旋转来对齐其主要方向，并单独使用。SIFT是对稀疏宽基准匹配进行优化的，R-HOG是空间形式的密集稳健编码。其他的先驱包括[4]的边缘方向直方图。我们通常使用平方R-HOG's，即，ς×ς网格的η×η像素cells，每个包含β个方向bins, 其中ς, η, β是参数。

Fig. 5 plots the miss rate at 10^−4 FPPW w.r.t. cell size and block size in cells. For human detection, 3×3 cell blocks of 6×6 pixel cells perform best, with 10.4% miss-rate at 10^−4 FPPW. Our standard 2×2 cell blocks of 8×8 cells are a close second. In fact, 6–8 pixel wide cells do best irrespective of the block size – an interesting coincidence as human limbs are about 6–8 pixels across in our images. 2×2 and 3×3 cell blocks work best. Adaptivity to local imaging conditions is weakened when the block becomes too big, and when it is too small (1×1 cell block, i.e. normalization over orientation alone) valuable spatial information is suppressed.

图5画出了在不同cell大小和block大小时10^-4 FPPW时的miss率。对于人体检测，3x3的cell blocks，6x6像素的cells性能最好，10^-4 FPPW时的miss率为10.4%。我们标准的2x2 cell blocks，8x8像素的cells，是很接近的第二。实际上，6-8像素宽的cells效果最好，与block大小无关，而在我们的图像中，人体肢体的长度大约是6-8像素，这是一个很有趣的巧合。2x2和3x3的cell blocks效果最好。当block变的太大时，对局部成像条件的适应性就变差了，而当block大小时（1x1 cell block，即，只对方向进行归一化），宝贵的空间信息就被抑制了。

As in [12], it is useful to downweight pixels near the edges of the block by applying a Gaussian spatial window to each pixel before accumulating orientation votes into cells. This improves performance by 1% at 10^−4 FPPW for a Gaussian with σ = 0.5 ∗ block width.

和[12]中一样，对block边缘的像素进行弱加权，是有用的，即对每个像素使用一个高斯空间窗，然后再将方向投票累积成cells。对于σ = 0.5 ∗ block宽度的高斯函数，在10^-4 FPPW时，性能改进了1%。

We also tried including multiple block types with different cell and block sizes in the overall descriptor. This slightly improves performance (by around 3% at 10^−4 FPPW), at the cost of greatly increased descriptor size.

我们还尝试了在整体描述子之中包含了多个block类型，有不同的cell和block大小。这略微改进了性能，而代价则是极大增加了描述子的大小。

Besides square R-HOG blocks, we also tested vertical (2×1 cell) and horizontal (1×2 cell) blocks and a combined descriptor including both vertical and horizontal pairs. Vertical and vertical+horizontal pairs are significantly better than horizontal pairs alone, but not as good as 2×2 or 3×3 cell blocks (1% worse at 10−4 FPPW).

除了方形的R-HOG blocks，我们还测试了竖直的(2x1 cell)和水平的(1x2 cell) blocks，和一个结合的描述子，同时包含竖直的和水平的对。竖直的和竖直+水平的对，比水平的要明显要好，但没有2x2或3x3 cell blocks要好。

**C-HOG**. Our circular block (C-HOG) descriptors are reminiscent of Shape Contexts [1] except that, crucially, each spatial cell contains a stack of gradient-weighted orientation cells instead of a single orientation-independent edge-presence count. The log-polar grid was originally suggested by the idea that it would allow fine coding of nearby structure to be combined with coarser coding of wider context, and the fact that the transformation from the visual field to the V1 cortex in primates is logarithmic [21]. However small descriptors with very few radial bins turn out to give the best performance, so in practice there is little inhomogeneity or context. It is probably better to think of C-HOG’s simply as an advanced form of centre-surround coding.

我们的圆形block (C-HOG)描述子和Shape Contexts类似，但是每个空间cell包含了很多梯度加权的方向cells，而不是单个的与方向无关的边缘存在数量。Log-polar网格是受到下面思想启发的，即可以使附近结构的精细编码与更宽的上下文的粗糙编码结合起来，而且视野到V1 cortex的变换就是对数型的。但是，很少径向bins的小型描述子结果性能最好，所以实践中，不均匀性或上下文非常少。将C-HOG视为圆形环绕的编码的高级形式更好一些。

We evaluated two variants of the C-HOG geometry, ones with a single circular central cell (similar to the GLOH feature of [14]), and ones whose central cell is divided into angular sectors as in shape contexts. We present results only for the circular-centre variants, as these have fewer spatial cells than the divided centre ones and give the same performance in practice. A technical report will provide further details. The C-HOG layout has four parameters: the numbers of angular and radial bins; the radius of the central bin in pixels; and the expansion factor for subsequent radii. At least two radial bins (a centre and a surround) and four angular bins (quartering) are needed for good performance. Including additional radial bins does not change the performance much, while increasing the number of angular bins decreases performance (by 1.3% at 10^−4 FPPW when going from 4 to 12 angular bins). 4 pixels is the best radius for the central bin, but 3 and 5 give similar results. Increasing the expansion factor from 2 to 3 leaves the performance essentially unchanged. With these parameters, neither Gaussian spatial weighting nor inverse weighting of cell votes by cell area changes the performance, but combining these two reduces slightly. These values assume fine orientation sampling. Shape contexts (1 orientation bin) require much finer spatial subdivision to work well.

我们评估了C-HOG几何的两种变体，一种是单个圆形的中心cell，一个是中心cell分割成角形扇区，和shape context一样。我们只给出了圆形中央的变体的结果，因为空间cells数量更少，而且实践中性能一样。另一篇科技报告给出更多细节。C-HOG有4个参数：角形数量，径向bins数量；中央bin的半径，单位为像素；后续半径的展开系数。至少需要2个径向bins和4个角形bins才能得到很好的性能。更多的径向bins不会很大的改进性能，而增加角形bins的数量会降低性能。中央bin的半径的最佳数值为4个像素，但3和5的结果也类似。将扩展系数从2增加到3，性能没有任何改变。有了这些参数，高斯空间加权，或cell投票的逆加权，都不会改变性能，但将这二者结合会使得性能略微下降。这些值假设有精细的方向采样。Shape context（1个方向bin），需要更加精细的空间分割，才能得到很好的结果。

**Block Normalization schemes**. We evaluated four different block normalization schemes for each of the above HOG geometries. Let v be the unnormalized descriptor vector, ||v||_k be its k-norm for k=1, 2, and ϵ be a small constant. The schemes are: (a) L2-norm, v → v/$\sqrt {||v||^2_2 + ϵ^2}$; (b) L2-Hys, L2-norm followed by clipping (limiting the maximum values of v to 0.2) and renormalizing, as in [12]; (c) L1-norm, v → v/(||v||_1 + ϵ); and (d) L1-sqrt, L1-norm followed by square root v → $\sqrt {v/(||v||_1 + ϵ}$, which amounts to treating the descriptor vectors as probability distributions and using the Bhattacharya distance between them. Fig. 4(c) shows that L2-Hys, L2-norm and L1-sqrt all perform equally well, while simple L1-norm reduces performance by 5%, and omitting normalization entirely reduces it by 27%, at 10^−4 FPPW. Some regularization ϵ is needed as we evaluate descriptors densely, including on empty patches, but the results are insensitive to ϵ’s value over a large range.

**Block归一化方案**。对每个上述HOG几何，我们评估了四种不同的block归一化方案。令v是未归一化的描述子向量，||v||_k是k-范数，k=1或2，ϵ是一个小常数。方案是：(a)L2范数，v → v/$\sqrt {||v||^2_2 + ϵ^2}$；(b)L2-Hys，L2-范数后进行剪切，使v的最大值为0.2，和重新归一化，和[12]中一样；(c)L1范数，v → v/(||v||_1 + ϵ)；(d)L1-sqrt，L1范数后求开方，v → $\sqrt {v/(||v||_1 + ϵ}$，即将描述子向量堪称概率分布，在其中使用Bhattacharya距离。图4c表明，L2-Hys，L2-norm和L1-sqrt表现都很好，而简单的L1-norm使性能下降约5%，完全忽略归一化则降低了27%。需要一些正则化，因为我们密集计算描述子，包括空的图像块，但结果对ϵ的值并不敏感。

**Centre-surround normalization**. We also investigated an alternative centre-surround style cell normalization scheme, in which the image is tiled with a grid of cells and for each cell the total energy in the cell and its surrounding region (summed over orientations and pooled using Gaussian weighting) is used to normalize the cell. However as fig. 4(c) (“window norm”) shows, this decreases performance relative to the corresponding block based scheme (by 2% at 10^−4 FPPW, for pooling with σ=1 cell widths). One reason is that there are no longer any overlapping blocks so each cell is coded only once in the final descriptor. Including several normalizations for each cell based on different pooling scales σ provides no perceptible change in performance, so it seems that it is the existence of several pooling regions with different spatial offsets relative to the cell that is important here, not the pooling scale.

To clarify this point, consider the R-HOG detector with overlapping blocks. The coefficients of the trained linear SVM give a measure of how much weight each cell of each block can have in the final discrimination decision. Close examination of fig. 6(b,f) shows that the most important cells are the ones that typically contain major human contours (especially the head and shoulders and the feet), normalized w.r.t. blocks lying outside the contour. In other words — despite the complex, cluttered backgrounds that are common in our training set — the detector cues mainly on the contrast of silhouette contours against the background, not on internal edges or on silhouette contours against the foreground. Patterned clothing and pose variations may make internal regions unreliable as cues, or foreground-to-contour transitions may be confused by smooth shading and shadowing effects. Similarly, fig. 6(c,g) illustrate that gradients inside the person (especially vertical ones) typically count as negative cues, presumably because this suppresses false positives in which long vertical lines trigger vertical head and leg cells.

### 6.5 Detector Window and Context

Our 64×128 detection window includes about 16 pixels of margin around the person on all four sides. Fig. 4(e) shows that this border provides a significant amount of context that helps detection. Decreasing it from 16 to 8 pixels (48×112 detection window) decreases performance by 4% at 10^−4 FPPW. Keeping a 64×128 window but increasing the person size within it (again decreasing the border) causes a similar loss of performance, even though the resolution of the person is actually increased.

我们的64x128检测窗口，在完整的人体四边周围，还有16个像素的margin。图4e展示了，这个边缘给出了很多context，可以帮助检测。从16像素降低到8像素（28x112检测窗口），使得性能下降4%。保持64x128的窗口，但增加人体的大小，会导致类似的性能下降，即使人体的分辨率实际上是增加的。

### 6.6 Classifier

By default we use a soft (C=0.01) linear SVM trained with SVMLight [10] (slightly modified to reduce memory usage for problems with large dense descriptor vectors). Using a Gaussian kernel SVM increases performance by about 3% at 10^−4 FPPW at the cost of a much higher run time.

默认我们使用软线性SVM。使用高斯核SVM会提升3%的性能，但代价是极大的增加了复杂度。

### 6.7 Discussion

Overall, there are several notable findings in this work. The fact that HOG greatly out-performs wavelets and that any significant degree of smoothing before calculating gradients damages the HOG results emphasizes that much of the available image information is from abrupt edges at fine scales, and that blurring this in the hope of reducing the sensitivity to spatial position is a mistake. Instead, gradients should be calculated at the finest available scale in the current pyramid layer, rectified or used for orientation voting, and only then blurred spatially. Given this, relatively coarse spatial quantization suffices (6–8 pixel wide cells / one limb width). On the other hand, at least for human detection, it pays to sample orientation rather finely: both wavelets and shape contexts lose out significantly here.

总体上，本文中有几个值得提到的发现。HOG比小波的效果要好，在计算梯度之前的任意平滑都会使HOG结果下降，说明很多可用的图像信息都是精细尺度的突然的边缘，对此进行模糊，以降低对空间位置的敏感性，是一个错误。梯度应当在尽可能精细的尺度上进行计算，用于方向投票，然后再空间上进行模糊。给定了这些，相对粗糙的空间量化才可以满足需要。另一方面，至少是对于人体检测，方向的采样更精细会有额外的代价：小波和shape contexts都明显损失了性能。

Secondly, strong local contrast normalization is essential for good results, and traditional centre-surround style schemes are not the best choice. Better results can be achieved by normalizing each element (edge, cell) several times with respect to different local supports, and treating the results as independent signals. In our standard detector, each HOG cell appears four times with different normalizations and including this ‘redundant’ information improves performance from 84% to 89% at 10^−4 FPPW.

第二，很强的局部对比度归一化，对于好的结果是不可或缺的，传统的中间环绕式的方案并不是最佳的选择。更好的结果可以通过对不同的局部支撑归一化每个元素几次得到，并将结果视为独立的信号。在我们的标准检测器中，每个HOG cell都出现了4次，有着不同的归一化，包含这种冗余信息使性能从84%改进到89%。

## 7 Summary and Conclusions

We have shown that using locally normalized histogram of gradient orientations features similar to SIFT descriptors [12] in a dense overlapping grid gives very good results for person detection, reducing false positive rates by more than an order of magnitude relative to the best Haar wavelet based detector from [17]. We studied the influence of various descriptor parameters and concluded that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good performance. We also introduced a new and more challenging pedestrian database, which is publicly available.

我们展示了，使用局部归一化的梯度方向直方图，这与SIFT描述子类似，但是是在密集叠加网格上的，对人体检测会得到很好的结果，与表现最好的Haar小波相比，降低了假阳性率一个数量级。我们研究了各种描述子参数的影响，得出结论，精细的梯度，精细的方向binning，相对粗糙的空间binning，高质量局部对比度归一化，对于好的性能来说都是很重要的。我们还提出了一个新的更有挑战性的行人数据集，已经公开可用。

**Future work**: Although our current linear SVM detector is reasonably efficient – processing a 320×240 scale-space image (4000 detection windows) in less than a second – there is still room for optimization and to further speed up detections it would be useful to develop a coarse-to-fine or rejection-chain style detector based on HOG descriptors. We are also working on HOG-based detectors that incorporate motion information using block matching or optical flow fields. Finally, although the current fixed-template-style detector has proven difficult to beat for fully visible pedestrians, humans are highly articulated and we believe that including a parts based model with a greater degree of local spatial invariance would help to improve the detection results in more general situations.

未来工作：虽然我们现在的线性SVM检测器非常高效，处理320x240的尺度空间图像，4000个检测窗口，时间小于1秒，但仍然有优化的空间，为进一步加速检测，基于HOG描述子开发由粗糙到精细的或拒绝链式的检测器是有用的。我们还在开发基于HOG的，纳入运动信息的检测器，使用block匹配或光流场。最后，虽然目前的固定模板式的检测器对于完整可见的行人很有效，但人体是高度铰接的，我们相信包含基于部位的模型，局部空间不变性更强，会帮助改进更加通用情况的检测结果。